{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, QuantileTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve, auc, cohen_kappa_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from drawdata import draw_line, draw_scatter, draw_histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the following cell, you can draw a data scatter plot, try creating data points where the decision boundary is not linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_scatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the data is not showing or you are getting an error, you can use the following code to load the data\n",
    "df = pd.read_csv('data/polynomial_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the data is not linearly separable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can experimente with the following too\n",
    "# draw_line(), draw_histogram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the data above, press \"copy csv\" and then run the following code to get the data into a pandas dataframe.\n",
    "# df = pd.read_clipboard(sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['z'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('z', axis=1)\n",
    "y = df['z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Scatter plot of X1 vs X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21, stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline([\n",
    "    ('scaler', QuantileTransformer(n_quantiles=100)),\n",
    "    ('model', LogisticRegression(solver='liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__penalty': ['l1', 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.title('Scatter plot of X1 vs X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(model_pipeline, params, cv=5, scoring='accuracy')\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix: {confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_score(y_test, y_pred)}\")\n",
    "print(f\"Classification Report: {classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the scatter plot of predicted vs actual\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred)\n",
    "plt.title('Predicted vs Actual')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_params = {\n",
    "    'poly__degree': [2, 3, 4, 5, 10],\n",
    "    'scaler__n_quantiles': [100, 1000],\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100, 250, 500, 1000],\n",
    "    # 'model__penalty': ['l1', 'l2'],\n",
    "    # 'model__solver': ['liblinear', 'lbfgs', 'saga']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's convert features to polynomial features\n",
    "model_pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures()),\n",
    "    ('scaler', QuantileTransformer()),\n",
    "    ('model', LogisticRegression(max_iter=2000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(model_pipeline, poly_params, \n",
    "                        #   n_iter=100, \n",
    "                          cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification Report: \\n{classification_report(y_test, y_pred)}\")\n",
    "# plot the scatter plot of predicted vs actual\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred)\n",
    "plt.title('Predicted vs Actual')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on the entire dataset\n",
    "y_pred = best_model.predict(X)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred)\n",
    "plt.title('Predicted')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.title('Actual')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare it to SVC with a linear kernel and a polynomial kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_linear_pipeline = Pipeline([\n",
    "    ('scaler', QuantileTransformer()),\n",
    "    ('model', SVC(kernel='linear'))\n",
    "])\n",
    "\n",
    "svc_linear_params = {\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__gamma': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "svcl_grid = GridSearchCV(svc_linear_pipeline, svc_linear_params, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "svcl_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = svcl_grid.best_estimator_\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification Report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "# plot the scatter plot of predicted vs actual\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred)\n",
    "plt.title('Predicted vs Actual')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try the rbf kernel\n",
    "svc_poly_pipeline = Pipeline([\n",
    "    ('scaler', QuantileTransformer()),\n",
    "    ('model', SVC(kernel='poly'))\n",
    "])\n",
    "\n",
    "svc_poly_params = {\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__gamma': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__degree': [2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "svp_grid = GridSearchCV(svc_poly_pipeline, svc_poly_params, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "svp_grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = svp_grid.best_estimator_\n",
    "best_model\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification Report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "# plot the scatter plot of predicted vs actual\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred)\n",
    "plt.title('Predicted vs Actual')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as we can see, the linear kernel is not able to separate the data, but the polynomial kernel is able to do so. \\\n",
    "Whilst the polynomial kernel gives a better result, it is also more computationally expensive; \\\n",
    "To get the best of both worlds, we can use the RBF kernel, which is able to separate the data and is also computationally efficient, as we will see in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try the rbf kernel\n",
    "svc_rbf_pipeline = Pipeline([\n",
    "    ('scaler', QuantileTransformer()),\n",
    "    ('model', SVC(kernel='rbf'))\n",
    "])\n",
    "\n",
    "svc_rbf_params = {\n",
    "    'model__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'model__gamma': [0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "svcr_grid = GridSearchCV(svc_rbf_pipeline, svc_rbf_params, cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "svcr_grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = svcr_grid.best_estimator_\n",
    "best_model\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"Confusion Matrix: \\n{confusion_matrix(y_test, y_pred)}\")\n",
    "print(f\"Classification Report: \\n{classification_report(y_test, y_pred)}\")\n",
    "\n",
    "# plot the scatter plot of predicted vs actual\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_pred)\n",
    "plt.title('Predicted vs Actual')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the RBF kernel is able to separate the data really well, and it is also computationally efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict on the entire dataset\n",
    "y_pred = best_model.predict(X)\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_pred)\n",
    "plt.title('Predicted')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.title('Actual')\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearningITS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
